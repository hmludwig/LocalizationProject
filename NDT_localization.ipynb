{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.autograd import Variable\n",
    "import tools.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib import animation, rc\n",
    "from torch.optim import LBFGS\n",
    "import numpy as np\n",
    "from IPython.display import display, Math, Latex, Markdown, HTML\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pcd = torch.tensor(utils.pcl_from_pcd(\"../dataset/map.pcd\"), device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the floor points\n",
    "z_min = torch.min(target_pcd[:,2])\n",
    "print(z_min)\n",
    "threshold = -1\n",
    "target_pcd = target_pcd[target_pcd[:,2] > threshold]\n",
    "target_pcd = target_pcd[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDT_map():\n",
    "    def __init__(self, grid_map, means, covs, counts, resolution, x_min, y_min, distributions) -> None:\n",
    "        self.grid_map = grid_map\n",
    "        self.means = means\n",
    "        self.covs = covs\n",
    "        self.counts = counts\n",
    "        self.nx = grid_map.shape[0]\n",
    "        self.ny = grid_map.shape[1]\n",
    "        self.x_min = x_min\n",
    "        self.y_min = y_min\n",
    "        self.resolution = resolution\n",
    "        self.distributions = distributions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize(pcd, x_min, x_max, y_min, y_max, resolution):\n",
    "    \"\"\"\n",
    "    Voxelize a point cloud.\n",
    "    Args:\n",
    "        pcd: point cloud, shape (N, 3)\n",
    "        x_min, x_max, y_min, y_max: voxelization range\n",
    "        resolution: voxel size\n",
    "    Returns:\n",
    "        voxelized pcd, shape (N, 3)\n",
    "    \"\"\"\n",
    "    points = pcd.clone()\n",
    "    map = torch.zeros(\n",
    "        (nx := int(torch.ceil((x_max - x_min) / resolution)),\n",
    "        ny := int(torch.ceil((y_max - y_min) / resolution)), 2), device=device, dtype=torch.float32)\n",
    "    # write cell centers to map\n",
    "    map[:,:,0], map[:,:,1] = torch.meshgrid(\n",
    "        torch.arange(x_min, x_max, resolution, device=device),\n",
    "        torch.arange(y_min, y_max, resolution, device=device)\n",
    "        )\n",
    "    offset = torch.zeros((1,2), device=device, dtype=torch.float32)\n",
    "    offset[0,0] = x_min\n",
    "    offset[0,1] = y_min\n",
    "    pcd = pcd - offset\n",
    "    pcd = pcd / resolution\n",
    "    pcd = pcd.round()\n",
    "    pcd[:,0] = torch.clamp(pcd[:,0], 0, nx-1)\n",
    "    pcd[:,1] = torch.clamp(pcd[:,1], 0, ny-1)\n",
    "    pcd = pcd.to(torch.int64)\n",
    "\n",
    "    pcd_ = torch.unique(pcd, dim=0)\n",
    "    counts_map = torch.zeros((nx,ny), device=device, dtype=torch.int64)\n",
    "\n",
    "    means = torch.zeros((map.shape[0],map.shape[1],2), device=device, dtype=torch.float32)\n",
    "    covs = torch.zeros((map.shape[0],map.shape[1],2,2), device=device, dtype=torch.float32)\n",
    "    distributions = np.zeros((map.shape[0],map.shape[1]), dtype=object)\n",
    "\n",
    "    sizes = []\n",
    "    for idx in pcd_:\n",
    "        # repeat icd to get the same shape as points\n",
    "        idx = idx.repeat(points.shape[0], 1)\n",
    "        point_group = points[torch.all(pcd == idx, dim=1),:]\n",
    "        sizes.append(point_group.shape[0])\n",
    "        if point_group.shape[0] <= 4:\n",
    "            continue\n",
    "        cov = torch.cov(point_group.T)\n",
    "        covs[idx[0,0], idx[0,1], :] = torch.cov(point_group.T)\n",
    "        means[idx[0,0], idx[0,1], :] = point_group.mean(dim=0)\n",
    "        counts_map[idx[0,0], idx[0,1]] = point_group.shape[0]\n",
    "        distributions[idx[0,0], idx[0,1]] = MultivariateNormal(means[idx[0,0], idx[0,1], :], covs[idx[0,0], idx[0,1], :])\n",
    "    assert sum(sizes) == points.shape[0]\n",
    "\n",
    "    ndt_map = NDT_map(map, means, covs, counts_map, resolution, x_min, y_min, distributions)\n",
    "\n",
    "    return ndt_map\n",
    "\n",
    "def calculate_score(reference_map: NDT_map, source_pcd: torch.Tensor, t: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Function to calculate the score of the alignment of the source_pcd to the reference_map\n",
    "\n",
    "    Args:\n",
    "        reference_map (NDT_map): reference map\n",
    "        source_pcd (torch.Tensor): source point cloud\n",
    "        t (torch.Tensor): transformation parameters\n",
    "    \"\"\"\n",
    "    R = torch.zeros(2, 2, device=device, dtype=torch.float32)\n",
    "    R[0, 0] = torch.cos(t[2])\n",
    "    R[0, 1] = -torch.sin(t[2])\n",
    "    R[1, 0] = torch.sin(t[2])\n",
    "    R[1, 1] = torch.cos(t[2])\n",
    "    source_pcd = source_pcd @ R + t[:2]\n",
    "\n",
    "    points = source_pcd.clone()\n",
    "    # mapping points from the source_pcd to the grid of the reference map\n",
    "    source_pcd = source_pcd - torch.tensor([reference_map.x_min, reference_map.y_min], device=device, dtype=torch.float32)\n",
    "    source_pcd = source_pcd / reference_map.resolution\n",
    "    source_pcd = source_pcd.round()\n",
    "    # only keep cells that are in the map\n",
    "    #mask = torch.tensor((source_pcd[:,0] > 0) & (source_pcd[:,0] < reference_map.nx-1) &\n",
    "    #    (source_pcd[:,1] > 0) & (source_pcd[:,1] < reference_map.ny-1), device=device, dtype=torch.bool)\n",
    "    #source_pcd = source_pcd[mask]\n",
    "    #points = points[mask]\n",
    "    source_pcd[:,0] = torch.clamp(source_pcd[:,0], 0, reference_map.nx-1)\n",
    "    source_pcd[:,1] = torch.clamp(source_pcd[:,1], 0, reference_map.ny-1)\n",
    "    source_pcd = source_pcd.to(torch.int32)\n",
    "\n",
    "    # get the unique points\n",
    "    source_pcd_ = torch.unique(source_pcd, dim=0)\n",
    "    \n",
    "    score = torch.tensor(0, device=device, dtype=torch.float32, requires_grad=True)\n",
    "    k = 0\n",
    "    for idx in source_pcd_:\n",
    "        # active points\n",
    "        idx = idx.repeat(points.shape[0], 1)\n",
    "        act_points = points[torch.all(source_pcd == idx, dim=1),:].requires_grad_(True)\n",
    "        \n",
    "        if reference_map.counts[idx[0,0],idx[0,1]] <= 4:\n",
    "            score = score - 100*act_points.shape[0]\n",
    "            continue\n",
    "        distribution = reference_map.distributions[idx[0,0],idx[0,1]]\n",
    "        k += act_points.shape[0]\n",
    "        # evaluate distribution for each point\n",
    "        score = score + distribution.log_prob(act_points).sum()\n",
    "    score = score / k\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max, y_min, y_max = torch.min(target_pcd[:,0]), torch.max(target_pcd[:,0]), torch.min(target_pcd[:,1]), torch.max(target_pcd[:,1])\n",
    "ndt_map = voxelize(target_pcd, x_min=x_min, x_max=x_max, y_min=y_min, y_max=y_max, resolution = 4.854255375398731)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ndt(ndt_map: NDT_map):\n",
    "    map = ndt_map.grid_map\n",
    "    means = ndt_map.means\n",
    "    covs = ndt_map.covs\n",
    "    counts = ndt_map.counts\n",
    "    nx = ndt_map.nx\n",
    "    ny = ndt_map.ny\n",
    "    resolution = ndt_map.resolution\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    # plot rectangles around cells\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            if counts.cpu().numpy()[i,j] == 0:\n",
    "                continue\n",
    "            plt.plot(\n",
    "            [map.cpu().numpy()[i,j,0]-resolution/2, map.cpu().numpy()[i,j,0]+resolution/2, map.cpu().numpy()[i,j,0]+resolution/2, map.cpu().numpy()[i,j,0]-resolution/2, map.cpu().numpy()[i,j,0]-resolution/2],\n",
    "            [map.cpu().numpy()[i,j,1]-resolution/2, map.cpu().numpy()[i,j,1]-resolution/2, map.cpu().numpy()[i,j,1]+resolution/2, map.cpu().numpy()[i,j,1]+resolution/2, map.cpu().numpy()[i,j,1]-resolution/2],\n",
    "            color='black', alpha=0.1\n",
    "            )\n",
    "            \n",
    "    # draw covs\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            if np.allclose(covs.cpu().numpy()[i,j,:], np.zeros((2,2))):\n",
    "                continue\n",
    "            a,b,c = covs.cpu().numpy()[i,j,0,0],covs.cpu().numpy()[i,j,0,1],covs.cpu().numpy()[i,j,1,1]\n",
    "            width = (a+c)/2 + np.sqrt(((a-c)/2)**2 + b**2)\n",
    "            height = (a+c)/2 - np.sqrt(((a-c)/2)**2 + b**2)\n",
    "            width, height  = sorted([width, height])\n",
    "            assert height > width\n",
    "            width = max(width, 0.1)\n",
    "            plt.gca().add_patch(Ellipse(\n",
    "            xy=(means.cpu().numpy()[i,j,0], means.cpu().numpy()[i,j,1]),\n",
    "            width= height,\n",
    "            height= width,\n",
    "            angle=np.arctan2(\n",
    "            height - a, b\n",
    "            ) * 180 / np.pi,\n",
    "            color='blue'\n",
    "        ))\n",
    "            \n",
    "    plt.axis('equal')\n",
    "\n",
    "plot_ndt(ndt_map)\n",
    "\n",
    "# load a frame\n",
    "frame = 70\n",
    "source_pcd = torch.tensor(utils.pcl_from_pcd(f\"../dataset/frames/frame_{frame}.pcd\"), device=device, dtype=torch.float32, requires_grad=True)\n",
    "threshold = -1.5\n",
    "source_pcd = source_pcd[source_pcd[:,2] > threshold]\n",
    "source_pcd = source_pcd[:, :2]\n",
    "\n",
    "# translate\n",
    "t = torch.tensor([0, 0, 0], device=device, dtype=torch.float32, requires_grad=True)\n",
    "rotation_matrix = torch.tensor([[torch.cos(t[2]), -torch.sin(t[2])], [torch.sin(t[2]), torch.cos(t[2])]], device=device, requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "plt.plot(\n",
    "    (source_pcd @ rotation_matrix).cpu().detach().numpy()[:,0]+t[:2].cpu().detach().numpy()[0],\n",
    "    (source_pcd @ rotation_matrix).cpu().detach().numpy()[:,1]+t[:2].cpu().detach().numpy()[1], 'o', color='red', alpha=0.005\n",
    ")\n",
    "\n",
    "\n",
    "score = calculate_score(ndt_map, source_pcd, t)\n",
    "score.backward(retain_graph=True)\n",
    "print(f\"{score=}\")\n",
    "\n",
    "\n",
    "print(t.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/ground_truth.csv\")\n",
    "gt = df[[\"x\", \"y\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ndt_map, frame, init_value):\n",
    "    # load a frame\n",
    "    source_pcd = torch.tensor(utils.pcl_from_pcd(f\"../dataset/frames/frame_{frame}.pcd\"), device=device, dtype=torch.float32)\n",
    "    source_pcd = source_pcd[source_pcd[:,2] > threshold]\n",
    "    source_pcd = source_pcd[:, :2].clone().requires_grad_(True)\n",
    "    t = torch.tensor([init_value[0], init_value[1], init_value[2]], device=device, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "    j = 0\n",
    "    t_ = t.detach().clone()\n",
    "    scores = []\n",
    "    vals = []\n",
    "    while True:\n",
    "        score = calculate_score(ndt_map, source_pcd, t)\n",
    "        scores.append(score.cpu().detach().numpy())\n",
    "        vals.append(t.cpu().detach().numpy())\n",
    "        score.backward()\n",
    "        def calculate_score_mod(t, ndt_map=ndt_map, source_pcd = source_pcd):\n",
    "            return calculate_score(ndt_map, source_pcd, t)\n",
    "        \n",
    "        try:\n",
    "            dt = (torch.linalg.inv(torch.autograd.functional.hessian(calculate_score_mod, t.detach())) @ t.grad)\n",
    "        except:\n",
    "            dt = torch.rand(3, device=device, dtype=torch.float32)*0.05\n",
    "        \n",
    "        t = (t - dt).detach()\n",
    "        \n",
    "        if (torch.linalg.norm(dt) < 1e-2) or j > 2:\n",
    "            if torch.max(t - t_) > 0.6:\n",
    "                return t_.cpu().detach().numpy(), j\n",
    "            break\n",
    "        j += 1\n",
    "    del source_pcd\n",
    "    t_best = np.array(vals[(pos := np.argmin(scores))])\n",
    "\n",
    "    return t_best, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max, y_min, y_max = torch.min(target_pcd[:,0]), torch.max(target_pcd[:,0]), torch.min(target_pcd[:,1]), torch.max(target_pcd[:,1])\n",
    "ndt_map = voxelize(target_pcd, x_min=x_min, x_max=x_max, y_min=y_min, y_max=y_max, resolution =  4.854255375398731)\n",
    "\n",
    "track = []\n",
    "\n",
    "start = 0\n",
    "val = [*gt[start],0]\n",
    "for idx in range(start, gt.shape[0]):\n",
    "    acc = 0\n",
    "    vel = 0\n",
    "    if len(track) > 20:\n",
    "        # linear extrapolation\n",
    "        val = (track[-1] + \n",
    "                (vel := (-1*track[-20]+track[-1])/(19)) + \n",
    "                (acc := (9*track[-20]-19*track[-10]+10*track[-1])/(855*2)))\n",
    "    val, its = train(ndt_map, idx, val)\n",
    "    print(f\"idx {idx} iterations {its} error:\", error := np.linalg.norm(val[:2]-gt[idx]), f\"t: {val}, acc: {acc}, vel: {vel}\")\n",
    "\n",
    "    if error > 3:\n",
    "        print(\"way too big\")\n",
    "        break\n",
    "    track.append(val)\n",
    "\n",
    "track = np.array(track)\n",
    "df = pd.DataFrame(track, columns=[\"x\", \"y\", \"theta\"])\n",
    "df.to_csv(\"track.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def animate_track(ndt_map: NDT_map, track=None):\n",
    "    img = mpimg.imread('../Car-Top-View.png')\n",
    "    img = np.flipud(img)\n",
    "\n",
    "    extent = [-1.4, 1.4, -2.70, 2.7]\n",
    "    map = ndt_map.grid_map\n",
    "    means = ndt_map.means\n",
    "    covs = ndt_map.covs\n",
    "    counts = ndt_map.counts\n",
    "    nx = ndt_map.nx\n",
    "    ny = ndt_map.ny\n",
    "    resolution = ndt_map.resolution\n",
    "    \n",
    "    fig,axs = plt.subplots(1, 2, figsize=(25,6), gridspec_kw={'width_ratios': [3, 1]})\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    fig.suptitle(\"Visualization of the NDT map and the track\", fontsize=16)\n",
    "    \n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            if counts.cpu().numpy()[i,j] == 0:\n",
    "                continue\n",
    "            axs[0].plot(\n",
    "                [map.cpu().numpy()[i,j,0]-resolution/2, map.cpu().numpy()[i,j,0]+resolution/2, map.cpu().numpy()[i,j,0]+resolution/2, map.cpu().numpy()[i,j,0]-resolution/2, map.cpu().numpy()[i,j,0]-resolution/2],\n",
    "                [map.cpu().numpy()[i,j,1]-resolution/2, map.cpu().numpy()[i,j,1]-resolution/2, map.cpu().numpy()[i,j,1]+resolution/2, map.cpu().numpy()[i,j,1]+resolution/2, map.cpu().numpy()[i,j,1]-resolution/2],\n",
    "                color='black', alpha=0.1\n",
    "            )\n",
    "\n",
    "    reference = utils.pcl_from_pcd(\"../dataset/map.pcd\")[:, :2]\n",
    "    axs[0].plot(reference[:,0], reference[:,1],'o', color='black',  alpha=0.002, label=\"reference map\")\n",
    "    \n",
    "    \n",
    "    data = utils.pcl_from_pcd(f\"../dataset/frames/frame_{0}.pcd\")\n",
    "    (measurement,) = axs[0].plot(data[:,0], data[:,1], 'o', color='red', alpha=0.01, label=\"measured points\")\n",
    "    (ground_truth,) = axs[0].plot(gt[:1,0], gt[:1,1], color='green', label=\"ground truth\")\n",
    "    leg = axs[0].legend()\n",
    "\n",
    "    for lh in leg.legendHandles: \n",
    "        lh.set_alpha(1)\n",
    "    axs[1].imshow(img, alpha=0.5,extent=extent, origin='upper')\n",
    "    axs[1].axis('equal')\n",
    "\n",
    "    axs[1].set_xlabel(\"lateral error [m]\")\n",
    "    axs[1].set_ylabel(\"longitudinal error [m]\")\n",
    "\n",
    "    (error, ) = axs[1].plot([], [], color='red')\n",
    "\n",
    "    def animate(frame):\n",
    "        print(f\"starting frame: {frame}\")\n",
    "        t = track[frame]\n",
    "        rotation_matrix = np.array([[np.cos(t[2]), -np.sin(t[2])], [np.sin(t[2]), np.cos(t[2])]])\n",
    "        data = utils.pcl_from_pcd(f\"../dataset/frames/frame_{frame}.pcd\")[:,:2]\n",
    "        data = data @ rotation_matrix\n",
    "        measurement.set_data(data[:,0]+t[0], data[:,1]+t[1])\n",
    "        ground_truth.set_data(gt[:frame,0], gt[:frame,1])\n",
    "\n",
    "        plot_len = np.clip(frame-50, 0, frame-50)\n",
    "        error.set_data(track[plot_len: frame,1]-gt[plot_len:frame,1], track[plot_len: frame,0]-gt[plot_len: frame,0])\n",
    "        return (measurement,ground_truth, error)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(track),\n",
    "                                    blit=True, interval=50)\n",
    "    # save the animation as mp4 video file\n",
    "    anim.save(\"ndt_animation.mp4\", fps=60, extra_args=[\"-vcodec\", \"libx264\"])\n",
    "    #return HTML(anim.to_jshtml())\n",
    "    \n",
    "    \n",
    "animate_track(ndt_map, track)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
